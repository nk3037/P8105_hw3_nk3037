---
title: "P8105_hw3_nk3037"
author: "Navya Koneripalli"
date: "2023-10-11"
output: github_document
---
## Setup
```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library (ggplot2)
knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 12, 
  fig.height = 8,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Question 1
```{r}
data("instacart")

instacart = 
  instacart |> 
  as_tibble()
frequency_table <- table(instacart$product_name)

most_ordered_item <- names(frequency_table)[which.max(frequency_table)]
# Created a variable to store the most ordered item
```
The dataset has `r nrow(instacart)` rows and `r ncol(instacart)` columns. Each row in the dataset represents a product in an order. Besides having columns that identify orders and products, the dataset has columns that tell us the order that the product was added to cart, whether it was reordered or not, order time, department and aisle name and id of the product.The dataset contains information for `r instacart %>% select(order_id) %>% distinct() %>% count()` orders from `r instacart %>% select(department) %>% distinct() %>% count()` departments. The most ordered item is `r most_ordered_item`.

This table below shows the number of aisles and the most commonly ordered items:
```{r}
instacart |> 
  count(aisle) |> 
  arrange(desc(n))
```

The plot below shows the number of items ordered in each aisle
```{r}
instacart %>% 
  count(aisle) %>%
  filter (aisle > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

The table shows the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits” and include the number of times each item is ordered.
```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>%  
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>% 
  knitr::kable()
```

The table shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week 
```{r, message=FALSE}
instacart %>% 
  filter(product_name %in% c("Coffee Ice Cream","Pink Lady Apples")) %>% 
  group_by(product_name, order_dow) %>%
  summarize(avg_tod = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = avg_tod) %>% 
  knitr::kable()
```

## Question 2
### Setup and Data Cleaning
```{r}
library(p8105.datasets)
data("brfss_smart2010")

brfss_smart2010 = janitor::clean_names(brfss_smart2010, case = "snake") #convert all variable names into snake_case

brfss_smart2010 = brfss_smart2010 %>% 
  rename(state = locationabbr) %>% 
  rename(county = locationdesc)
# renamed Locationabbr to state and Locationdesc to county.

brfss_smart2010 <- brfss_smart2010 %>% 
  filter(topic == "Overall Health") %>% 
  filter(response %in% c("Excellent", "Very good", "Good", "Fair", "Poor")) %>% 
  arrange(factor(response, levels = c("Poor", "Fair good", "Good", "Very good", "Excellent")))
# Filtered to keep only overall health topic, and those with Poor to Excellent responses and arranged the responses from Poor to Excellent
```

This tells us in 2002, which states were observed at 7 or more locations
```{r}
brfss_filtered_2002 = brfss_smart2010 %>% 
  filter(year == 2002) %>% 
  group_by(state) %>%
  summarise(count = n_distinct(county)) %>% 
  filter (count >= 7)
```

In 2002, `r nrow(brfss_filtered_2002)` states were observed at 7 or more counties. The states are **CT, FL, MA, NC, NJ, PA**

This tells us in 2010, which states were observed at 7 or more locations
```{r}
brfss_filtered_2010 = brfss_smart2010 %>% 
  filter(year == 2010) %>% 
  group_by(state) %>%
  summarise(count = n_distinct(county)) %>% 
  filter (count >= 7)
```

In 2002, `r nrow(brfss_filtered_2010)` states were observed at 7 or more counties. The states are: **CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA**.

The code chunk below constructs a dataset that is limited to "Excellent" responses, and contains, year, state, and a variable that averages the crude prevalence (%) across locations within a state. Then, a “spaghetti” plot is made showing the average crude prevalence (%) over time within a state.
```{r, message = FALSE}
brfss_state_trend = brfss_smart2010 %>%
  filter(response == "Excellent") %>%
  group_by(year, state) %>%
  summarise(avg_data_value = mean(data_value))
# created a new dataset limited to Excellent responses and contains year, state and created a new variable avg_data_value that averages data_value across counties in a state

brfss_state_trend %>% 
  ggplot(aes(x = year, y = avg_data_value, color = state, group = state)) +
  geom_line()+
  labs(
    title = "Average crude prevalence (%) trends in 50 US states (and DC) between 2002 and 2010",
    x = "Year",
    y = "Average crude prevalence (%)"
  ) +
 theme(legend.position = "right")
```

The `avg_data_value` values for most the states are generally concentrated between 20-25% across the 2002-2010 time period. Alaska in 2005 is a outlier, where the crude prevalence (%) across AK counties went down to about 12%. In general, AK has had lower average crude prevalence (%) than the other states throughout the 2002-2010 period. With so many states being displayed on the same graph, in this case a spaghetti plot is very difficult to read. There does not seem to be much of an increase or decrease in the average crude prevalence (%) across the time period.

Below is a two-panel plot that shows, for the years 2006 and 2010, the distribution of crude prevalence (%) for responses (“Poor” to “Excellent”) among counties in NY State.
```{r}
brfss_smart2010 %>% 
  filter(state == "NY") %>% 
  filter(year %in% c(2006, 2010)) %>% 
  ggplot(aes(x = data_value, fill = response, color = response)) +
  geom_density(alpha = 0.75) +
  facet_wrap(~year, ncol = 2) +
  labs(
    title = "Distribution of crude prevalence (%) by response in New York State (2006 vs 2010)",
    x = "Crude prevalence (%)",
    y = "Frequency"
  )
```

The two side by side plots show the distribution of responses as they relate to crude prevalence in 2006 and 2010.In 2006 and 2010, The lower the crude prevalence, the higher the frequency of "Poor" responses. In 2010, the spread of "Poor" responses is over a slightly wider range of crude prevalence rates compared to 2006 (2-5% in 2006 and 2-8% in 2010). There are also fewer "Poor" and "Fair" responses and more "Good" responses between 2006 and 2010. Generally, the distribuition curves all apprear to have shifted right, indicating improving health overall.

## Question 3
### Setup
```{r}
# Loading the datasets
nhanes_covar = 
  read.csv("./data/nhanes_covar.csv", skip = 4)
nhanes_covar = janitor::clean_names(nhanes_covar, case = "snake")
nhanes_accel = 
   read.csv("./data/nhanes_accel.csv")
nhanes_accel = janitor::clean_names(nhanes_accel, case = "snake")

# Tidying the datasets
nhanes_covar = nhanes_covar %>% 
  mutate(
    sex = recode(sex, "1" = "Male", "2" = "Female"), 
    education = recode(education, "1" = "Less than high school", "2" = "High school equivalent", "3" = "More than high school")
    )
# Merging the datasets
merged_nhanes = inner_join(nhanes_covar, nhanes_accel, by = "seqn")

merged_nhanes = merged_nhanes %>% 
  filter(age >= 21) %>% 
  filter(!is.na(sex) & !is.na(age) & !is.na(bmi) & !is.na(education)) 
```

This produces a table for the number of men and women in each education category, and creates a visualization of the age distributions for men and women in each education category.
```{r, message = FALSE}
# Counting the number of men and women in each education category
merged_nhanes %>%
  group_by(sex, education) %>% 
  summarize(count = n()) %>%
  pivot_wider(names_from = sex, values_from = count) %>% 
  arrange(factor(education, levels = c("Less than high school", "High school equivalent", "More than high school")))
```
The table above shows that approximately the same number of men and women had less than a high school education and more than a high school education. However, more men had a high school equivalent level of education than women (35 men and 23 women). 

This aggregates across minutes to create a total activity variable for each participant and then plots these total activities against age
```{r, message = FALSE}
merged_nhanes %>% 
  group_by(seqn, sex, education, age) %>% 
  summarize(total_activity = sum(min1:min1440)) %>%
  ggplot(aes(x = age, y = total_activity, color = sex)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  facet_grid(education ~ .) +
  labs(
    title = "Total Activity over the day by age, gender and education level",
    x = "Age",
    y = "Total activity in the day"
  ) +
  scale_y_continuous(
  limits = c(0,100)
  )
```
The graph above shows the trends in activity over the day by age, gender and education level. Males and females with high school equivalent education had similar trends in activity in the day over age. There is a slight negative correlation between age and total activity.

For those with less than high school education, males had higher total activity in the day than females for all ages. However around age 80, males and females had similar total activity in the day. There is a slight negative correlation between age and total activity for males and slight positive correlation for females.

Lastly, for those with more than high school education, females generally had higher total activity for the day when compared to males.Around age 80, the trend lines for males and females converges. There is a negative correlation between age and total activity for the day in males and females.